
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-24 13:36:39.406104: do_dummy_2d_data_aug: False 
2025-02-24 13:37:06.145110: Using splits from existing split file: /content/drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset001_BoneScanAnterior/splits_final.json 
2025-02-24 13:37:06.868186: The split file contains 1 splits. 
2025-02-24 13:37:06.871905: Desired fold for training: 0 
2025-02-24 13:37:06.874307: This split has 1658 training and 90 validation cases. 
2025-02-24 13:41:27.604493: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 48, 'patch_size': [512, 128], 'median_image_size_in_voxels': [512.0, 128.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BoneScanAnterior', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 128], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 220.8397674560547, 'median': 229.0, 'min': 0.0, 'percentile_00_5': 88.0, 'percentile_99_5': 255.0, 'std': 30.951431274414062}}} 
 
2025-02-24 13:41:33.635541: unpacking dataset... 
2025-02-24 13:44:01.970135: unpacking done... 
2025-02-24 13:44:05.001869: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-02-24 13:44:06.273638:  
2025-02-24 13:44:06.277735: Epoch 0 
2025-02-24 13:44:06.281356: Current learning rate: 0.01 
2025-02-24 13:53:58.119514: train_loss 0.5959 
2025-02-24 13:53:58.127173: val_loss 0.1709 
2025-02-24 13:53:58.134287: Pseudo dice [0.1746, 0.0, 0.0, 0.8424, 0.5104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3298, 0.4148] 
2025-02-24 13:53:58.139736: Epoch time: 591.85 s 
2025-02-24 13:53:58.145093: Yayy! New best EMA pseudo Dice: 0.1893 
2025-02-24 13:54:28.918174:  
2025-02-24 13:54:28.960470: Epoch 1 
2025-02-24 13:54:28.967978: Current learning rate: 0.00999 
2025-02-24 14:01:41.312118: train_loss -0.1386 
2025-02-24 14:01:41.318702: val_loss -0.4521 
2025-02-24 14:01:41.322159: Pseudo dice [0.9328, 0.6701, 0.4653, 0.8731, 0.7987, 0.0, 0.3869, 0.8215, 0.7504, 0.77, 0.8268, 0.8616] 
2025-02-24 14:01:41.329699: Epoch time: 432.4 s 
2025-02-24 14:01:41.340037: Yayy! New best EMA pseudo Dice: 0.2384 
2025-02-24 14:01:45.723261:  
2025-02-24 14:01:45.729293: Epoch 2 
2025-02-24 14:01:45.736752: Current learning rate: 0.00998 
2025-02-24 14:08:55.017237: train_loss -0.6003 
2025-02-24 14:08:55.026305: val_loss -0.6553 
2025-02-24 14:08:55.036560: Pseudo dice [0.9493, 0.7697, 0.6235, 0.8925, 0.819, 0.7074, 0.7662, 0.8415, 0.8387, 0.8231, 0.8842, 0.876] 
2025-02-24 14:08:55.044354: Epoch time: 429.3 s 
2025-02-24 14:08:55.053420: Yayy! New best EMA pseudo Dice: 0.2961 
2025-02-24 14:09:01.331993:  
2025-02-24 14:09:01.338664: Epoch 3 
2025-02-24 14:09:01.346377: Current learning rate: 0.00997 
2025-02-24 14:16:09.465806: train_loss -0.6672 
2025-02-24 14:16:09.474738: val_loss -0.6677 
2025-02-24 14:16:09.483313: Pseudo dice [0.9507, 0.7704, 0.6361, 0.8939, 0.8209, 0.714, 0.7761, 0.8503, 0.8344, 0.8237, 0.8953, 0.8729] 
2025-02-24 14:16:09.490096: Epoch time: 428.14 s 
2025-02-24 14:16:09.497490: Yayy! New best EMA pseudo Dice: 0.3485 
2025-02-24 14:16:14.314891:  
2025-02-24 14:16:14.321329: Epoch 4 
2025-02-24 14:16:14.327286: Current learning rate: 0.00996 
2025-02-24 14:23:17.384821: train_loss -0.6818 
2025-02-24 14:23:17.391548: val_loss -0.6762 
2025-02-24 14:23:17.400843: Pseudo dice [0.9521, 0.7793, 0.6242, 0.8946, 0.8241, 0.7222, 0.7787, 0.8574, 0.8395, 0.8221, 0.8994, 0.881] 
2025-02-24 14:23:17.408703: Epoch time: 423.07 s 
2025-02-24 14:23:17.413826: Yayy! New best EMA pseudo Dice: 0.3959 
2025-02-24 14:23:21.880269:  
2025-02-24 14:23:21.887133: Epoch 5 
2025-02-24 14:23:21.892764: Current learning rate: 0.00995 
2025-02-24 14:30:22.222043: train_loss -0.6906 
2025-02-24 14:30:22.229759: val_loss -0.6733 
2025-02-24 14:30:22.236104: Pseudo dice [0.9525, 0.7731, 0.6331, 0.8935, 0.8242, 0.7174, 0.7767, 0.8551, 0.8345, 0.828, 0.8982, 0.8771] 
2025-02-24 14:30:22.241815: Epoch time: 420.34 s 
2025-02-24 14:30:22.246732: Yayy! New best EMA pseudo Dice: 0.4385 
2025-02-24 14:30:26.741433:  
2025-02-24 14:30:26.749222: Epoch 6 
2025-02-24 14:30:26.756746: Current learning rate: 0.00995 
2025-02-24 14:37:28.062614: train_loss -0.6984 
2025-02-24 14:37:28.074212: val_loss -0.6739 
2025-02-24 14:37:28.081231: Pseudo dice [0.9528, 0.7809, 0.6273, 0.8932, 0.8234, 0.7138, 0.7841, 0.8575, 0.8352, 0.8183, 0.9014, 0.8798] 
2025-02-24 14:37:28.086599: Epoch time: 421.32 s 
2025-02-24 14:37:28.096734: Yayy! New best EMA pseudo Dice: 0.4769 
2025-02-24 14:37:32.824629:  
2025-02-24 14:37:32.831591: Epoch 7 
2025-02-24 14:37:32.839188: Current learning rate: 0.00994 
2025-02-24 14:44:39.721862: train_loss -0.7054 
2025-02-24 14:44:39.733736: val_loss -0.6685 
2025-02-24 14:44:39.738786: Pseudo dice [0.952, 0.7735, 0.6196, 0.8905, 0.8164, 0.7111, 0.7662, 0.8552, 0.8324, 0.8259, 0.8996, 0.8802] 
2025-02-24 14:44:39.747185: Epoch time: 426.9 s 
2025-02-24 14:44:39.752993: Yayy! New best EMA pseudo Dice: 0.5111 
2025-02-24 14:44:45.809949:  
2025-02-24 14:44:45.826870: Epoch 8 
2025-02-24 14:44:45.838967: Current learning rate: 0.00993 
2025-02-24 14:51:43.566645: train_loss -0.7118 
2025-02-24 14:51:43.573269: val_loss -0.6602 
2025-02-24 14:51:43.580665: Pseudo dice [0.9526, 0.7671, 0.5877, 0.8893, 0.8133, 0.7106, 0.7659, 0.8527, 0.8383, 0.8194, 0.8978, 0.8755] 
2025-02-24 14:51:43.588890: Epoch time: 417.76 s 
2025-02-24 14:51:43.594065: Yayy! New best EMA pseudo Dice: 0.5414 
2025-02-24 14:51:48.130495:  
2025-02-24 14:51:48.137364: Epoch 9 
2025-02-24 14:51:48.143425: Current learning rate: 0.00992 
2025-02-24 14:58:45.228533: train_loss -0.7197 
2025-02-24 14:58:45.252161: val_loss -0.664 
2025-02-24 14:58:45.257582: Pseudo dice [0.9514, 0.7679, 0.6096, 0.8909, 0.818, 0.706, 0.7699, 0.8608, 0.8268, 0.8253, 0.8987, 0.8829] 
2025-02-24 14:58:45.262689: Epoch time: 417.1 s 
2025-02-24 14:58:45.271149: Yayy! New best EMA pseudo Dice: 0.569 
2025-02-24 14:58:49.902505:  
2025-02-24 14:58:49.909764: Epoch 10 
2025-02-24 14:58:49.914778: Current learning rate: 0.00991 
2025-02-24 15:05:58.958117: train_loss -0.7254 
2025-02-24 15:05:58.966636: val_loss -0.6579 
2025-02-24 15:05:58.973832: Pseudo dice [0.9513, 0.7689, 0.5982, 0.8873, 0.8104, 0.6993, 0.7618, 0.8587, 0.8294, 0.8156, 0.9004, 0.8829] 
2025-02-24 15:05:58.981175: Epoch time: 429.06 s 
2025-02-24 15:05:58.987556: Yayy! New best EMA pseudo Dice: 0.5935 
2025-02-24 15:06:04.262770:  
2025-02-24 15:06:04.269619: Epoch 11 
2025-02-24 15:06:04.275930: Current learning rate: 0.0099 
2025-02-24 15:13:07.789727: train_loss -0.7303 
2025-02-24 15:13:07.801672: val_loss -0.664 
2025-02-24 15:13:07.810832: Pseudo dice [0.9535, 0.7706, 0.6133, 0.8913, 0.8168, 0.7057, 0.7638, 0.858, 0.8321, 0.8231, 0.9011, 0.8813] 
2025-02-24 15:13:07.823590: Epoch time: 423.53 s 
2025-02-24 15:13:07.831718: Yayy! New best EMA pseudo Dice: 0.6159 
2025-02-24 15:13:12.842330:  
2025-02-24 15:13:12.864858: Epoch 12 
2025-02-24 15:13:12.870608: Current learning rate: 0.00989 
2025-02-24 15:20:06.726462: train_loss -0.7367 
2025-02-24 15:20:06.746023: val_loss -0.6601 
2025-02-24 15:20:06.751321: Pseudo dice [0.9515, 0.7698, 0.6112, 0.8884, 0.8139, 0.703, 0.7664, 0.857, 0.8316, 0.8216, 0.9008, 0.8809] 
2025-02-24 15:20:06.759578: Epoch time: 413.89 s 
2025-02-24 15:20:06.764005: Yayy! New best EMA pseudo Dice: 0.6359 
2025-02-24 15:20:12.622120:  
2025-02-24 15:20:12.635826: Epoch 13 
2025-02-24 15:20:12.643075: Current learning rate: 0.00988 
2025-02-24 15:26:58.938357: train_loss -0.7418 
2025-02-24 15:26:58.963069: val_loss -0.6555 
2025-02-24 15:26:58.968667: Pseudo dice [0.952, 0.7699, 0.5844, 0.8867, 0.8054, 0.7049, 0.7711, 0.8587, 0.8368, 0.8222, 0.8984, 0.8759] 
2025-02-24 15:26:58.974892: Epoch time: 406.32 s 
2025-02-24 15:26:58.979934: Yayy! New best EMA pseudo Dice: 0.6537 
2025-02-24 15:27:04.662572:  
2025-02-24 15:27:04.670737: Epoch 14 
2025-02-24 15:27:04.677482: Current learning rate: 0.00987 
2025-02-24 15:33:58.288619: train_loss -0.7463 
2025-02-24 15:33:58.296881: val_loss -0.6532 
2025-02-24 15:33:58.304747: Pseudo dice [0.9516, 0.7675, 0.6137, 0.8878, 0.8083, 0.6942, 0.7641, 0.8603, 0.8287, 0.8182, 0.9003, 0.8825] 
2025-02-24 15:33:58.312976: Epoch time: 413.63 s 
2025-02-24 15:33:58.319974: Yayy! New best EMA pseudo Dice: 0.6698 
2025-02-24 15:34:03.444207:  
2025-02-24 15:34:03.450557: Epoch 15 
2025-02-24 15:34:03.455325: Current learning rate: 0.00986 
2025-02-24 15:41:09.031826: train_loss -0.7506 
2025-02-24 15:41:09.039201: val_loss -0.6487 
2025-02-24 15:41:09.048412: Pseudo dice [0.952, 0.7602, 0.5962, 0.8841, 0.808, 0.695, 0.7592, 0.8576, 0.8319, 0.8164, 0.8991, 0.8786] 
2025-02-24 15:41:09.056164: Epoch time: 425.59 s 
2025-02-24 15:41:09.064225: Yayy! New best EMA pseudo Dice: 0.684 
2025-02-24 15:41:15.384908:  
2025-02-24 15:41:15.391101: Epoch 16 
2025-02-24 15:41:15.416652: Current learning rate: 0.00986 
2025-02-24 15:48:27.378796: train_loss -0.755 
2025-02-24 15:48:27.387534: val_loss -0.6388 
2025-02-24 15:48:27.393194: Pseudo dice [0.9506, 0.7656, 0.5831, 0.8843, 0.805, 0.6989, 0.7615, 0.8547, 0.8309, 0.8136, 0.8939, 0.8733] 
2025-02-24 15:48:27.402145: Epoch time: 432.0 s 
2025-02-24 15:48:27.410121: Yayy! New best EMA pseudo Dice: 0.6965 
2025-02-24 15:48:32.927163:  
2025-02-24 15:48:32.935327: Epoch 17 
2025-02-24 15:48:32.939172: Current learning rate: 0.00985 
2025-02-24 15:55:36.753837: train_loss -0.7585 
2025-02-24 15:55:36.759348: val_loss -0.6464 
2025-02-24 15:55:36.765831: Pseudo dice [0.9507, 0.7669, 0.5848, 0.8883, 0.8159, 0.6984, 0.7632, 0.8553, 0.8258, 0.8142, 0.8985, 0.8771] 
2025-02-24 15:55:36.772712: Epoch time: 423.83 s 
2025-02-24 15:55:36.778533: Yayy! New best EMA pseudo Dice: 0.7081 
2025-02-24 15:55:43.087682:  
2025-02-24 15:55:43.094965: Epoch 18 
2025-02-24 15:55:43.101995: Current learning rate: 0.00984 
2025-02-24 16:02:53.079507: train_loss -0.7624 
2025-02-24 16:02:53.086192: val_loss -0.6458 
2025-02-24 16:02:53.092259: Pseudo dice [0.9529, 0.7609, 0.5823, 0.8849, 0.8102, 0.7062, 0.7682, 0.8571, 0.8386, 0.8156, 0.8977, 0.8744] 
2025-02-24 16:02:53.100792: Epoch time: 429.99 s 
2025-02-24 16:02:53.106668: Yayy! New best EMA pseudo Dice: 0.7185 
2025-02-24 16:02:59.372665:  
2025-02-24 16:02:59.389012: Epoch 19 
2025-02-24 16:02:59.396576: Current learning rate: 0.00983 
2025-02-24 16:10:00.823388: train_loss -0.7654 
2025-02-24 16:10:00.829423: val_loss -0.6412 
2025-02-24 16:10:00.835501: Pseudo dice [0.9519, 0.763, 0.5963, 0.8877, 0.8133, 0.6977, 0.7629, 0.8578, 0.8299, 0.8121, 0.8974, 0.8763] 
2025-02-24 16:10:00.840669: Epoch time: 421.45 s 
2025-02-24 16:10:00.846486: Yayy! New best EMA pseudo Dice: 0.7279 
2025-02-24 16:10:05.563610:  
2025-02-24 16:10:05.576806: Epoch 20 
2025-02-24 16:10:05.580088: Current learning rate: 0.00982 
2025-02-24 16:17:08.785446: train_loss -0.7671 
2025-02-24 16:17:08.792792: val_loss -0.6445 
2025-02-24 16:17:08.801231: Pseudo dice [0.9526, 0.766, 0.5844, 0.8876, 0.81, 0.7002, 0.7708, 0.8604, 0.8271, 0.8146, 0.901, 0.8822] 
2025-02-24 16:17:08.806901: Epoch time: 423.22 s 
2025-02-24 16:17:08.812362: Yayy! New best EMA pseudo Dice: 0.7364 
2025-02-24 16:17:14.699651:  
2025-02-24 16:17:14.711601: Epoch 21 
2025-02-24 16:17:14.723830: Current learning rate: 0.00981 
2025-02-24 16:24:10.456528: train_loss -0.7708 
2025-02-24 16:24:10.481685: val_loss -0.6407 
2025-02-24 16:24:10.487418: Pseudo dice [0.9536, 0.7682, 0.5569, 0.8868, 0.8104, 0.6984, 0.766, 0.857, 0.8278, 0.8125, 0.8988, 0.8776] 
2025-02-24 16:24:10.493042: Epoch time: 415.76 s 
2025-02-24 16:24:10.500064: Yayy! New best EMA pseudo Dice: 0.7437 
2025-02-24 16:24:15.050842:  
2025-02-24 16:24:15.058590: Epoch 22 
2025-02-24 16:24:15.065434: Current learning rate: 0.0098 
2025-02-24 16:31:13.174008: train_loss -0.7752 
2025-02-24 16:31:13.182895: val_loss -0.643 
2025-02-24 16:31:13.190854: Pseudo dice [0.9504, 0.7644, 0.6019, 0.8887, 0.8145, 0.7028, 0.7666, 0.8594, 0.8301, 0.8079, 0.899, 0.8801] 
2025-02-24 16:31:13.195315: Epoch time: 418.13 s 
2025-02-24 16:31:13.200849: Yayy! New best EMA pseudo Dice: 0.7507 
2025-02-24 16:31:17.584334:  
2025-02-24 16:31:17.613219: Epoch 23 
2025-02-24 16:31:17.621613: Current learning rate: 0.00979 
2025-02-24 16:38:17.273412: train_loss -0.7763 
2025-02-24 16:38:17.281332: val_loss -0.6286 
2025-02-24 16:38:17.289887: Pseudo dice [0.9515, 0.754, 0.568, 0.8852, 0.8096, 0.6927, 0.7541, 0.8534, 0.8329, 0.8094, 0.8971, 0.877] 
2025-02-24 16:38:17.297566: Epoch time: 419.69 s 
2025-02-24 16:38:17.307735: Yayy! New best EMA pseudo Dice: 0.7563 
2025-02-24 16:38:21.667980:  
2025-02-24 16:38:21.674735: Epoch 24 
2025-02-24 16:38:21.684010: Current learning rate: 0.00978 
2025-02-24 16:45:27.388964: train_loss -0.7796 
2025-02-24 16:45:27.397157: val_loss -0.6373 
2025-02-24 16:45:27.404392: Pseudo dice [0.9507, 0.7632, 0.6044, 0.8857, 0.8114, 0.7055, 0.7635, 0.8549, 0.8333, 0.8151, 0.8974, 0.8761] 
2025-02-24 16:45:27.410858: Epoch time: 425.72 s 
2025-02-24 16:45:27.416230: Yayy! New best EMA pseudo Dice: 0.762 
2025-02-24 16:45:31.731909:  
2025-02-24 16:45:31.738480: Epoch 25 
2025-02-24 16:45:31.745276: Current learning rate: 0.00977 
2025-02-24 16:52:33.672808: train_loss -0.7824 
2025-02-24 16:52:33.695666: val_loss -0.6222 
2025-02-24 16:52:33.703478: Pseudo dice [0.9512, 0.7585, 0.559, 0.8819, 0.8026, 0.6954, 0.7577, 0.8522, 0.829, 0.8102, 0.894, 0.8765] 
2025-02-24 16:52:33.710900: Epoch time: 421.94 s 
2025-02-24 16:52:33.718389: Yayy! New best EMA pseudo Dice: 0.7664 
2025-02-24 16:52:38.205296:  
2025-02-24 16:52:38.211126: Epoch 26 
2025-02-24 16:52:38.220764: Current learning rate: 0.00977 
2025-02-24 16:59:34.764168: train_loss -0.7843 
2025-02-24 16:59:34.772803: val_loss -0.6387 
2025-02-24 16:59:34.780220: Pseudo dice [0.9533, 0.7668, 0.5975, 0.889, 0.8122, 0.7017, 0.7645, 0.8561, 0.8294, 0.808, 0.9001, 0.8795] 
2025-02-24 16:59:34.785368: Epoch time: 416.56 s 
2025-02-24 16:59:34.795993: Yayy! New best EMA pseudo Dice: 0.7711 
2025-02-24 16:59:40.194883:  
2025-02-24 16:59:40.202177: Epoch 27 
2025-02-24 16:59:40.206597: Current learning rate: 0.00976 
2025-02-24 17:06:46.363416: train_loss -0.786 
2025-02-24 17:06:46.369492: val_loss -0.64 
2025-02-24 17:06:46.375939: Pseudo dice [0.953, 0.7682, 0.5993, 0.8885, 0.8143, 0.7033, 0.7676, 0.8571, 0.8346, 0.8148, 0.9009, 0.8776] 
2025-02-24 17:06:46.381936: Epoch time: 426.17 s 
2025-02-24 17:06:46.386912: Yayy! New best EMA pseudo Dice: 0.7755 
2025-02-24 17:06:50.862500:  
2025-02-24 17:06:50.870120: Epoch 28 
2025-02-24 17:06:50.890587: Current learning rate: 0.00975 
2025-02-24 17:13:49.783517: train_loss -0.7865 
2025-02-24 17:13:49.791000: val_loss -0.635 
2025-02-24 17:13:49.798488: Pseudo dice [0.9513, 0.7544, 0.6036, 0.889, 0.8158, 0.693, 0.7614, 0.8586, 0.8307, 0.8124, 0.9002, 0.8777] 
2025-02-24 17:13:49.807880: Epoch time: 418.92 s 
2025-02-24 17:13:49.816576: Yayy! New best EMA pseudo Dice: 0.7792 
2025-02-24 17:13:55.221060:  
2025-02-24 17:13:55.226637: Epoch 29 
2025-02-24 17:13:55.232324: Current learning rate: 0.00974 
2025-02-24 17:20:55.956355: train_loss -0.791 
2025-02-24 17:20:55.963951: val_loss -0.626 
2025-02-24 17:20:55.969683: Pseudo dice [0.952, 0.7593, 0.591, 0.8875, 0.8092, 0.6974, 0.7508, 0.8546, 0.8293, 0.8122, 0.8971, 0.876] 
2025-02-24 17:20:55.978151: Epoch time: 420.74 s 
2025-02-24 17:20:56.012566: Yayy! New best EMA pseudo Dice: 0.7822 
2025-02-24 17:21:02.775760:  
2025-02-24 17:21:02.794361: Epoch 30 
2025-02-24 17:21:02.800052: Current learning rate: 0.00973 
2025-02-24 17:28:07.806569: train_loss -0.7908 
2025-02-24 17:28:07.816659: val_loss -0.6086 
2025-02-24 17:28:07.826272: Pseudo dice [0.9516, 0.7624, 0.5557, 0.8774, 0.797, 0.6943, 0.7659, 0.8496, 0.8265, 0.8077, 0.8951, 0.8711] 
2025-02-24 17:28:07.835212: Epoch time: 425.03 s 
2025-02-24 17:28:07.841492: Yayy! New best EMA pseudo Dice: 0.7844 
2025-02-24 17:28:12.757697:  
2025-02-24 17:28:12.763986: Epoch 31 
2025-02-24 17:28:12.771216: Current learning rate: 0.00972 
2025-02-24 17:35:18.708083: train_loss -0.794 
2025-02-24 17:35:18.720716: val_loss -0.6232 
2025-02-24 17:35:18.749686: Pseudo dice [0.9518, 0.7659, 0.5741, 0.8853, 0.8124, 0.6959, 0.7544, 0.8541, 0.8294, 0.8098, 0.8955, 0.8764] 
2025-02-24 17:35:18.758376: Epoch time: 425.95 s 
2025-02-24 17:35:18.768661: Yayy! New best EMA pseudo Dice: 0.7869 
2025-02-24 17:35:23.312346:  
2025-02-24 17:35:23.319430: Epoch 32 
2025-02-24 17:35:23.326972: Current learning rate: 0.00971 
2025-02-24 17:42:22.650487: train_loss -0.7976 
2025-02-24 17:42:22.660813: val_loss -0.6165 
2025-02-24 17:42:22.669526: Pseudo dice [0.952, 0.7596, 0.5767, 0.8844, 0.8053, 0.6955, 0.7551, 0.8531, 0.8283, 0.8088, 0.8945, 0.8746] 
2025-02-24 17:42:22.680146: Epoch time: 419.34 s 
2025-02-24 17:42:22.687817: Yayy! New best EMA pseudo Dice: 0.7889 
2025-02-24 17:42:27.668697:  
2025-02-24 17:42:27.677075: Epoch 33 
2025-02-24 17:42:27.687491: Current learning rate: 0.0097 
2025-02-24 17:49:23.089680: train_loss -0.798 
2025-02-24 17:49:23.096192: val_loss -0.6201 
2025-02-24 17:49:23.105536: Pseudo dice [0.9519, 0.7609, 0.5869, 0.8865, 0.8136, 0.6972, 0.7558, 0.8542, 0.8338, 0.8121, 0.8941, 0.8703] 
2025-02-24 17:49:23.112326: Epoch time: 415.42 s 
2025-02-24 17:49:23.118436: Yayy! New best EMA pseudo Dice: 0.791 
2025-02-24 17:49:27.533878:  
2025-02-24 17:49:27.557757: Epoch 34 
2025-02-24 17:49:27.563989: Current learning rate: 0.00969 
2025-02-24 17:56:25.893808: train_loss -0.7989 
2025-02-24 17:56:25.907274: val_loss -0.613 
2025-02-24 17:56:25.915208: Pseudo dice [0.9519, 0.7605, 0.5651, 0.8847, 0.805, 0.6918, 0.7482, 0.8512, 0.8273, 0.807, 0.8955, 0.8739] 
2025-02-24 17:56:25.922350: Epoch time: 418.36 s 
2025-02-24 17:56:25.931943: Yayy! New best EMA pseudo Dice: 0.7924 
2025-02-24 17:56:32.403531:  
2025-02-24 17:56:32.413344: Epoch 35 
2025-02-24 17:56:32.418684: Current learning rate: 0.00968 
2025-02-24 18:03:28.823069: train_loss -0.8005 
2025-02-24 18:03:28.833073: val_loss -0.6134 
2025-02-24 18:03:28.840440: Pseudo dice [0.9521, 0.7608, 0.5712, 0.8858, 0.8074, 0.698, 0.7544, 0.8521, 0.8274, 0.8142, 0.8921, 0.871] 
2025-02-24 18:03:28.850544: Epoch time: 416.42 s 
2025-02-24 18:03:28.858936: Yayy! New best EMA pseudo Dice: 0.7939 
2025-02-24 18:03:33.626588:  
2025-02-24 18:03:33.632533: Epoch 36 
2025-02-24 18:03:33.638586: Current learning rate: 0.00968 
2025-02-24 18:10:28.836267: train_loss -0.8044 
2025-02-24 18:10:28.857975: val_loss -0.6034 
2025-02-24 18:10:28.865281: Pseudo dice [0.9522, 0.7559, 0.5628, 0.8815, 0.7965, 0.6909, 0.7577, 0.8543, 0.8218, 0.8172, 0.8964, 0.8733] 
2025-02-24 18:10:28.873699: Epoch time: 415.21 s 
2025-02-24 18:10:28.880142: Yayy! New best EMA pseudo Dice: 0.795 
2025-02-24 18:10:36.272897:  
2025-02-24 18:10:36.282647: Epoch 37 
2025-02-24 18:10:36.292223: Current learning rate: 0.00967 
2025-02-24 18:17:26.986144: train_loss -0.8076 
2025-02-24 18:17:26.995105: val_loss -0.6116 
2025-02-24 18:17:27.003608: Pseudo dice [0.9511, 0.7606, 0.5897, 0.8823, 0.8052, 0.7021, 0.7587, 0.8532, 0.8304, 0.8156, 0.8972, 0.8732] 
2025-02-24 18:17:27.009117: Epoch time: 410.72 s 
2025-02-24 18:17:27.015778: Yayy! New best EMA pseudo Dice: 0.7965 
2025-02-24 18:17:32.147873:  
2025-02-24 18:17:32.155221: Epoch 38 
2025-02-24 18:17:32.160936: Current learning rate: 0.00966 
2025-02-24 18:24:23.721250: train_loss -0.8093 
2025-02-24 18:24:23.729758: val_loss -0.5963 
2025-02-24 18:24:23.735183: Pseudo dice [0.9499, 0.7495, 0.5598, 0.8803, 0.8021, 0.6896, 0.7492, 0.8501, 0.8244, 0.808, 0.8933, 0.8727] 
2025-02-24 18:24:23.743864: Epoch time: 411.58 s 
2025-02-24 18:24:23.769332: Yayy! New best EMA pseudo Dice: 0.7971 
2025-02-24 18:24:28.553427:  
2025-02-24 18:24:28.558865: Epoch 39 
2025-02-24 18:24:28.565942: Current learning rate: 0.00965 
2025-02-24 18:31:21.922216: train_loss -0.8108 
2025-02-24 18:31:21.929126: val_loss -0.6071 
2025-02-24 18:31:21.936550: Pseudo dice [0.9507, 0.7495, 0.5803, 0.8825, 0.8076, 0.6897, 0.7585, 0.8537, 0.8303, 0.8131, 0.8974, 0.8745] 
2025-02-24 18:31:21.943561: Epoch time: 413.37 s 
2025-02-24 18:31:21.949528: Yayy! New best EMA pseudo Dice: 0.7981 
2025-02-24 18:31:28.587309:  
2025-02-24 18:31:28.600425: Epoch 40 
2025-02-24 18:31:28.609370: Current learning rate: 0.00964 
2025-02-24 18:38:19.742271: train_loss -0.8119 
2025-02-24 18:38:19.748489: val_loss -0.5883 
2025-02-24 18:38:19.774250: Pseudo dice [0.9521, 0.7477, 0.5316, 0.8814, 0.8001, 0.6856, 0.7422, 0.8496, 0.8253, 0.8066, 0.8905, 0.8653] 
2025-02-24 18:38:19.783138: Epoch time: 411.16 s 
2025-02-24 18:38:19.792096: Yayy! New best EMA pseudo Dice: 0.7981 
2025-02-24 18:38:24.939030:  
2025-02-24 18:38:24.966148: Epoch 41 
2025-02-24 18:38:24.973562: Current learning rate: 0.00963 
2025-02-24 18:45:24.087275: train_loss -0.8125 
2025-02-24 18:45:24.093161: val_loss -0.6015 
2025-02-24 18:45:24.098200: Pseudo dice [0.9499, 0.7557, 0.5736, 0.8831, 0.804, 0.689, 0.7553, 0.8517, 0.8229, 0.8101, 0.8969, 0.8728] 
2025-02-24 18:45:24.103324: Epoch time: 419.15 s 
2025-02-24 18:45:24.110619: Yayy! New best EMA pseudo Dice: 0.7989 
2025-02-24 18:45:30.299746:  
2025-02-24 18:45:30.305421: Epoch 42 
2025-02-24 18:45:30.313162: Current learning rate: 0.00962 
2025-02-24 18:52:30.439529: train_loss -0.814 
2025-02-24 18:52:30.448023: val_loss -0.5877 
2025-02-24 18:52:30.456999: Pseudo dice [0.9517, 0.7574, 0.5488, 0.8824, 0.8033, 0.6874, 0.7441, 0.8476, 0.8279, 0.8108, 0.892, 0.868] 
2025-02-24 18:52:30.463285: Epoch time: 420.14 s 
2025-02-24 18:52:30.469833: Yayy! New best EMA pseudo Dice: 0.7991 
2025-02-24 18:52:36.701713:  
2025-02-24 18:52:36.737553: Epoch 43 
2025-02-24 18:52:36.753570: Current learning rate: 0.00961 
2025-02-24 18:59:32.030346: train_loss -0.8161 
2025-02-24 18:59:32.036705: val_loss -0.6014 
2025-02-24 18:59:32.043821: Pseudo dice [0.9522, 0.757, 0.5648, 0.8833, 0.8073, 0.6909, 0.7482, 0.8524, 0.8287, 0.8138, 0.8927, 0.8715] 
2025-02-24 18:59:32.051357: Epoch time: 415.33 s 
2025-02-24 18:59:32.059153: Yayy! New best EMA pseudo Dice: 0.7998 
2025-02-24 18:59:36.953181:  
2025-02-24 18:59:36.959164: Epoch 44 
2025-02-24 18:59:36.963918: Current learning rate: 0.0096 
2025-02-24 19:06:31.281949: train_loss -0.8166 
2025-02-24 19:06:31.289262: val_loss -0.6021 
2025-02-24 19:06:31.298510: Pseudo dice [0.9503, 0.7577, 0.588, 0.8822, 0.8019, 0.6985, 0.7653, 0.855, 0.825, 0.8166, 0.8982, 0.8742] 
2025-02-24 19:06:31.306134: Epoch time: 414.33 s 
2025-02-24 19:06:31.311514: Yayy! New best EMA pseudo Dice: 0.8007 
2025-02-24 19:06:37.504256:  
2025-02-24 19:06:37.512555: Epoch 45 
2025-02-24 19:06:37.517709: Current learning rate: 0.00959 
2025-02-24 19:13:29.491747: train_loss -0.8176 
2025-02-24 19:13:29.513026: val_loss -0.6018 
2025-02-24 19:13:29.524147: Pseudo dice [0.9503, 0.7565, 0.5831, 0.8849, 0.8099, 0.6949, 0.7592, 0.8502, 0.8374, 0.8132, 0.8947, 0.873] 
2025-02-24 19:13:29.535041: Epoch time: 411.99 s 
2025-02-24 19:13:29.542554: Yayy! New best EMA pseudo Dice: 0.8015 
2025-02-24 19:13:34.086332:  
2025-02-24 19:13:34.093702: Epoch 46 
2025-02-24 19:13:34.100904: Current learning rate: 0.00959 
2025-02-24 19:20:28.815353: train_loss -0.8213 
2025-02-24 19:20:28.829051: val_loss -0.5916 
2025-02-24 19:20:28.838979: Pseudo dice [0.9497, 0.7539, 0.572, 0.8826, 0.8041, 0.6968, 0.7608, 0.8514, 0.8294, 0.818, 0.8969, 0.8717] 
2025-02-24 19:20:28.849769: Epoch time: 414.73 s 
2025-02-24 19:20:28.857434: Yayy! New best EMA pseudo Dice: 0.8021 
2025-02-24 19:20:33.342041:  
2025-02-24 19:20:33.347820: Epoch 47 
2025-02-24 19:20:33.353393: Current learning rate: 0.00958 
2025-02-24 19:27:27.600821: train_loss -0.822 
2025-02-24 19:27:27.607472: val_loss -0.5931 
2025-02-24 19:27:27.615283: Pseudo dice [0.951, 0.7608, 0.5822, 0.8851, 0.8061, 0.6931, 0.761, 0.8529, 0.8283, 0.8151, 0.8949, 0.8744] 
2025-02-24 19:27:27.624841: Epoch time: 414.26 s 
2025-02-24 19:27:27.630906: Yayy! New best EMA pseudo Dice: 0.8028 
2025-02-24 19:27:33.088511:  
2025-02-24 19:27:33.093936: Epoch 48 
2025-02-24 19:27:33.100250: Current learning rate: 0.00957 
2025-02-24 19:34:31.408867: train_loss -0.8231 
2025-02-24 19:34:31.421044: val_loss -0.5741 
2025-02-24 19:34:31.427711: Pseudo dice [0.95, 0.7399, 0.535, 0.8788, 0.798, 0.6793, 0.7437, 0.8467, 0.8213, 0.8076, 0.8929, 0.8715] 
2025-02-24 19:34:31.432773: Epoch time: 418.32 s 
2025-02-24 19:34:33.990903:  
2025-02-24 19:34:33.998241: Epoch 49 
2025-02-24 19:34:34.008029: Current learning rate: 0.00956 
2025-02-24 19:41:33.747592: train_loss -0.8235 
2025-02-24 19:41:33.756431: val_loss -0.5929 
2025-02-24 19:41:33.762967: Pseudo dice [0.951, 0.7506, 0.5673, 0.8846, 0.8131, 0.6901, 0.7551, 0.8522, 0.8263, 0.8121, 0.8966, 0.8736] 
2025-02-24 19:41:33.769715: Epoch time: 419.76 s 
2025-02-24 19:41:38.244722:  
2025-02-24 19:41:38.250111: Epoch 50 
2025-02-24 19:41:38.257123: Current learning rate: 0.00955 
2025-02-24 19:48:34.930270: train_loss -0.8266 
2025-02-24 19:48:34.938272: val_loss -0.5933 
2025-02-24 19:48:34.944957: Pseudo dice [0.9506, 0.7545, 0.5653, 0.8842, 0.809, 0.6855, 0.7539, 0.8546, 0.8262, 0.8141, 0.897, 0.8742] 
2025-02-24 19:48:34.953328: Epoch time: 416.69 s 
2025-02-24 19:48:34.959253: Yayy! New best EMA pseudo Dice: 0.8029 
2025-02-24 19:48:41.127479:  
2025-02-24 19:48:41.142773: Epoch 51 
2025-02-24 19:48:41.150750: Current learning rate: 0.00954 
2025-02-24 19:55:34.936058: train_loss -0.8284 
2025-02-24 19:55:34.942229: val_loss -0.5755 
2025-02-24 19:55:34.948946: Pseudo dice [0.9492, 0.7567, 0.5381, 0.8865, 0.8068, 0.6927, 0.7416, 0.8478, 0.8274, 0.8134, 0.8911, 0.8691] 
2025-02-24 19:55:34.956130: Epoch time: 413.81 s 
2025-02-24 19:55:37.338559:  
2025-02-24 19:55:37.345389: Epoch 52 
2025-02-24 19:55:37.352407: Current learning rate: 0.00953 
2025-02-24 20:02:33.508912: train_loss -0.8304 
2025-02-24 20:02:33.517137: val_loss -0.582 
2025-02-24 20:02:33.524310: Pseudo dice [0.9496, 0.749, 0.5595, 0.8851, 0.8104, 0.6857, 0.7512, 0.8492, 0.8287, 0.8149, 0.8937, 0.8722] 
2025-02-24 20:02:33.531928: Epoch time: 416.17 s 
2025-02-24 20:02:33.538184: Yayy! New best EMA pseudo Dice: 0.8029 
2025-02-24 20:02:39.592681:  
2025-02-24 20:02:39.602418: Epoch 53 
2025-02-24 20:02:39.615973: Current learning rate: 0.00952 
2025-02-24 20:09:33.723858: train_loss -0.8325 
2025-02-24 20:09:33.736754: val_loss -0.5891 
2025-02-24 20:09:33.742327: Pseudo dice [0.9499, 0.7567, 0.5785, 0.8843, 0.8086, 0.6857, 0.7566, 0.8532, 0.8181, 0.8111, 0.8979, 0.8754] 
2025-02-24 20:09:33.746573: Epoch time: 414.14 s 
2025-02-24 20:09:33.755167: Yayy! New best EMA pseudo Dice: 0.8033 
2025-02-24 20:09:38.036154:  
2025-02-24 20:09:38.041351: Epoch 54 
2025-02-24 20:09:38.045830: Current learning rate: 0.00951 
2025-02-24 20:16:38.168942: train_loss -0.8312 
2025-02-24 20:16:38.175297: val_loss -0.5805 
2025-02-24 20:16:38.185805: Pseudo dice [0.9493, 0.7537, 0.5642, 0.8859, 0.8056, 0.6902, 0.7538, 0.853, 0.8235, 0.8157, 0.8952, 0.8747] 
2025-02-24 20:16:38.196138: Epoch time: 420.14 s 
2025-02-24 20:16:38.217607: Yayy! New best EMA pseudo Dice: 0.8035 
2025-02-24 20:16:42.724070:  
2025-02-24 20:16:42.731707: Epoch 55 
2025-02-24 20:16:42.738680: Current learning rate: 0.0095 
2025-02-24 20:23:31.874351: train_loss -0.8337 
2025-02-24 20:23:31.881645: val_loss -0.5912 
2025-02-24 20:23:31.889858: Pseudo dice [0.9525, 0.7598, 0.5426, 0.8858, 0.8105, 0.6947, 0.7618, 0.8536, 0.834, 0.8248, 0.8985, 0.88] 
2025-02-24 20:23:31.896516: Epoch time: 409.15 s 
2025-02-24 20:23:31.901143: Yayy! New best EMA pseudo Dice: 0.804 
2025-02-24 20:23:37.928163:  
2025-02-24 20:23:37.949732: Epoch 56 
2025-02-24 20:23:37.955366: Current learning rate: 0.00949 
2025-02-24 20:30:27.719937: train_loss -0.8353 
2025-02-24 20:30:27.726625: val_loss -0.5804 
2025-02-24 20:30:27.732772: Pseudo dice [0.9509, 0.7531, 0.561, 0.8829, 0.808, 0.6879, 0.7505, 0.8501, 0.825, 0.8165, 0.8951, 0.8757] 
2025-02-24 20:30:27.739425: Epoch time: 409.79 s 
2025-02-24 20:30:27.745409: Yayy! New best EMA pseudo Dice: 0.804 
2025-02-24 20:30:32.302159:  
2025-02-24 20:30:32.308390: Epoch 57 
2025-02-24 20:30:32.316048: Current learning rate: 0.00949 
2025-02-24 20:37:20.185295: train_loss -0.8355 
2025-02-24 20:37:20.196711: val_loss -0.5897 
2025-02-24 20:37:20.205998: Pseudo dice [0.9482, 0.7573, 0.5939, 0.8872, 0.8143, 0.7, 0.7616, 0.8548, 0.831, 0.8195, 0.8996, 0.8758] 
2025-02-24 20:37:20.215197: Epoch time: 407.89 s 
2025-02-24 20:37:20.222780: Yayy! New best EMA pseudo Dice: 0.8048 
2025-02-24 20:37:25.503421:  
2025-02-24 20:37:25.509999: Epoch 58 
2025-02-24 20:37:25.515185: Current learning rate: 0.00948 
2025-02-24 20:44:10.190257: train_loss -0.8357 
2025-02-24 20:44:10.197259: val_loss -0.5683 
2025-02-24 20:44:10.203254: Pseudo dice [0.9492, 0.7618, 0.5661, 0.8821, 0.8069, 0.6807, 0.7476, 0.8514, 0.8293, 0.8124, 0.8923, 0.8711] 
2025-02-24 20:44:10.209382: Epoch time: 404.69 s 
2025-02-24 20:44:12.779172:  
2025-02-24 20:44:12.784822: Epoch 59 
2025-02-24 20:44:12.790382: Current learning rate: 0.00947 
2025-02-24 20:50:56.608792: train_loss -0.8375 
2025-02-24 20:50:56.616166: val_loss -0.5565 
2025-02-24 20:50:56.623526: Pseudo dice [0.9494, 0.7515, 0.5565, 0.8789, 0.7999, 0.6782, 0.7475, 0.8509, 0.8268, 0.8127, 0.8945, 0.8707] 
2025-02-24 20:50:56.629066: Epoch time: 403.83 s 
2025-02-24 20:50:59.100976:  
2025-02-24 20:50:59.125107: Epoch 60 
2025-02-24 20:50:59.131768: Current learning rate: 0.00946 
2025-02-24 20:57:56.183598: train_loss -0.8378 
2025-02-24 20:57:56.189873: val_loss -0.5558 
2025-02-24 20:57:56.215396: Pseudo dice [0.9492, 0.7515, 0.5574, 0.8811, 0.8061, 0.6868, 0.742, 0.8481, 0.8284, 0.817, 0.889, 0.8656] 
2025-02-24 20:57:56.222213: Epoch time: 417.08 s 
2025-02-24 20:58:00.403538:  
2025-02-24 20:58:00.409898: Epoch 61 
2025-02-24 20:58:00.415036: Current learning rate: 0.00945 
2025-02-24 21:05:18.319936: train_loss -0.8398 
2025-02-24 21:05:18.327071: val_loss -0.5779 
2025-02-24 21:05:18.333952: Pseudo dice [0.9513, 0.7564, 0.5548, 0.8832, 0.8041, 0.6937, 0.753, 0.8482, 0.8308, 0.8183, 0.8943, 0.8727] 
2025-02-24 21:05:18.340631: Epoch time: 437.92 s 
2025-02-24 21:05:21.695415:  
2025-02-24 21:05:21.710944: Epoch 62 
2025-02-24 21:05:21.717700: Current learning rate: 0.00944 
2025-02-24 21:12:10.924040: train_loss -0.8406 
2025-02-24 21:12:10.930439: val_loss -0.555 
2025-02-24 21:12:10.934779: Pseudo dice [0.9496, 0.7528, 0.5193, 0.8798, 0.7961, 0.6888, 0.744, 0.8493, 0.8234, 0.8153, 0.8908, 0.8714] 
2025-02-24 21:12:10.941655: Epoch time: 409.23 s 
2025-02-24 21:12:13.226632:  
2025-02-24 21:12:13.233378: Epoch 63 
2025-02-24 21:12:13.239375: Current learning rate: 0.00943 
2025-02-24 21:18:57.254341: train_loss -0.8423 
2025-02-24 21:18:57.265396: val_loss -0.5615 
2025-02-24 21:18:57.276038: Pseudo dice [0.9493, 0.7507, 0.5399, 0.8803, 0.7979, 0.681, 0.7458, 0.8486, 0.8245, 0.8187, 0.8931, 0.871] 
2025-02-24 21:18:57.284268: Epoch time: 404.03 s 
2025-02-24 21:19:00.692630:  
2025-02-24 21:19:00.713268: Epoch 64 
2025-02-24 21:19:00.718108: Current learning rate: 0.00942 
2025-02-24 21:25:41.842605: train_loss -0.8438 
2025-02-24 21:25:41.850246: val_loss -0.5699 
2025-02-24 21:25:41.857331: Pseudo dice [0.9491, 0.7547, 0.5633, 0.8816, 0.8, 0.6892, 0.7556, 0.853, 0.831, 0.8201, 0.8967, 0.8727] 
2025-02-24 21:25:41.863318: Epoch time: 401.15 s 
2025-02-24 21:25:44.324044:  
2025-02-24 21:25:44.338432: Epoch 65 
2025-02-24 21:25:44.345973: Current learning rate: 0.00941 
2025-02-24 21:32:28.710912: train_loss -0.844 
2025-02-24 21:32:28.721806: val_loss -0.5621 
2025-02-24 21:32:28.729026: Pseudo dice [0.9496, 0.7482, 0.5178, 0.8769, 0.7966, 0.6832, 0.7551, 0.8515, 0.8231, 0.8112, 0.8935, 0.8729] 
2025-02-24 21:32:28.737494: Epoch time: 404.39 s 
2025-02-24 21:32:33.281326:  
2025-02-24 21:32:33.289142: Epoch 66 
2025-02-24 21:32:33.295278: Current learning rate: 0.0094 
2025-02-24 21:39:18.148953: train_loss -0.8455 
2025-02-24 21:39:18.155802: val_loss -0.5712 
2025-02-24 21:39:18.163287: Pseudo dice [0.9514, 0.7545, 0.5543, 0.8854, 0.8086, 0.6979, 0.752, 0.8521, 0.8258, 0.8139, 0.8914, 0.8759] 
2025-02-24 21:39:18.171190: Epoch time: 404.87 s 
2025-02-24 21:39:20.764996:  
2025-02-24 21:39:20.770439: Epoch 67 
2025-02-24 21:39:20.796289: Current learning rate: 0.00939 
2025-02-24 21:46:04.458785: train_loss -0.8441 
2025-02-24 21:46:04.465911: val_loss -0.5583 
2025-02-24 21:46:04.472724: Pseudo dice [0.9512, 0.7577, 0.5536, 0.8841, 0.8091, 0.6837, 0.7428, 0.8501, 0.8291, 0.8123, 0.8923, 0.8703] 
2025-02-24 21:46:04.478545: Epoch time: 403.7 s 
2025-02-24 21:46:08.901932:  
2025-02-24 21:46:08.909427: Epoch 68 
2025-02-24 21:46:08.914903: Current learning rate: 0.00939 
2025-02-24 21:52:54.574516: train_loss -0.8475 
2025-02-24 21:52:54.582544: val_loss -0.573 
2025-02-24 21:52:54.591978: Pseudo dice [0.9498, 0.7552, 0.582, 0.8814, 0.8001, 0.6962, 0.7608, 0.8531, 0.8252, 0.8215, 0.8985, 0.8734] 
2025-02-24 21:52:54.596392: Epoch time: 405.67 s 
2025-02-24 21:52:57.180785:  
2025-02-24 21:52:57.204125: Epoch 69 
2025-02-24 21:52:57.211733: Current learning rate: 0.00938 
2025-02-24 21:59:40.855358: train_loss -0.8467 
2025-02-24 21:59:40.873746: val_loss -0.5536 
2025-02-24 21:59:40.884413: Pseudo dice [0.9476, 0.7514, 0.5519, 0.8783, 0.7972, 0.6897, 0.7575, 0.8478, 0.828, 0.8166, 0.8942, 0.8694] 
2025-02-24 21:59:40.892201: Epoch time: 403.68 s 
2025-02-24 21:59:44.795045:  
2025-02-24 21:59:44.800704: Epoch 70 
2025-02-24 21:59:44.805242: Current learning rate: 0.00937 
2025-02-24 22:06:38.162216: train_loss -0.8481 
2025-02-24 22:06:38.169025: val_loss -0.542 
2025-02-24 22:06:38.175022: Pseudo dice [0.9501, 0.7471, 0.5332, 0.8771, 0.7912, 0.6766, 0.7389, 0.8464, 0.8236, 0.8136, 0.8895, 0.8659] 
2025-02-24 22:06:38.180495: Epoch time: 413.37 s 
2025-02-24 22:06:41.664222:  
2025-02-24 22:06:41.698531: Epoch 71 
2025-02-24 22:06:41.706697: Current learning rate: 0.00936 
2025-02-24 22:13:31.670799: train_loss -0.8488 
2025-02-24 22:13:31.676857: val_loss -0.5516 
2025-02-24 22:13:31.683357: Pseudo dice [0.95, 0.7546, 0.5321, 0.8812, 0.7996, 0.6906, 0.7435, 0.8478, 0.8276, 0.8136, 0.8913, 0.8704] 
2025-02-24 22:13:31.704169: Epoch time: 410.01 s 
2025-02-24 22:13:34.244421:  
2025-02-24 22:13:34.250226: Epoch 72 
2025-02-24 22:13:34.254705: Current learning rate: 0.00935 
2025-02-24 22:20:23.902318: train_loss -0.849 
2025-02-24 22:20:23.918515: val_loss -0.5597 
2025-02-24 22:20:23.930616: Pseudo dice [0.9506, 0.7571, 0.569, 0.8821, 0.8059, 0.6997, 0.7573, 0.8504, 0.8265, 0.8207, 0.8922, 0.8731] 
2025-02-24 22:20:23.937067: Epoch time: 409.66 s 
2025-02-24 22:20:26.788229:  
2025-02-24 22:20:26.794433: Epoch 73 
2025-02-24 22:20:26.803494: Current learning rate: 0.00934 
