
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-25 10:09:43.945978: Using torch.compile... 
2025-02-25 10:09:58.854461: do_dummy_2d_data_aug: False 
2025-02-25 10:10:25.406100: Using splits from existing split file: /content/drive/MyDrive/nnUNet/nnUNet_preprocessed/Dataset002_BoneScanPosterior/splits_final.json 
2025-02-25 10:10:26.059718: The split file contains 1 splits. 
2025-02-25 10:10:26.063516: Desired fold for training: 0 
2025-02-25 10:10:26.066026: This split has 1576 training and 88 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 48, 'patch_size': [512, 128], 'median_image_size_in_voxels': [512.0, 128.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_BoneScanPosterior', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [999.0, 1.0, 1.0], 'original_median_shape_after_transp': [1, 512, 128], 'image_reader_writer': 'NaturalImage2DIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 255.0, 'mean': 217.958740234375, 'median': 228.0, 'min': 0.0, 'percentile_00_5': 84.0, 'percentile_99_5': 255.0, 'std': 33.05488586425781}}} 
 
2025-02-25 10:14:10.532425: unpacking dataset... 
2025-02-25 10:16:26.990372: unpacking done... 
2025-02-25 10:16:29.566193: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-02-25 10:16:30.338471:  
2025-02-25 10:16:30.342248: Epoch 15 
2025-02-25 10:16:30.345657: Current learning rate: 0.00986 
2025-02-25 10:23:44.997414: train_loss -0.6993 
2025-02-25 10:23:45.015910: val_loss -0.6403 
2025-02-25 10:23:45.022519: Pseudo dice [0.9548, 0.8403, 0.8651, 0.9061, nan, 0.4536, 0.8748, 0.8704, 0.8459, 0.8039, 0.8997, 0.8912] 
2025-02-25 10:23:45.030256: Epoch time: 434.66 s 
2025-02-25 10:23:45.035882: Yayy! New best EMA pseudo Dice: 0.715 
2025-02-25 10:23:49.717272:  
2025-02-25 10:23:49.739063: Epoch 16 
2025-02-25 10:23:49.748817: Current learning rate: 0.00986 
2025-02-25 10:30:27.040162: train_loss -0.7028 
2025-02-25 10:30:27.046909: val_loss -0.644 
2025-02-25 10:30:27.053485: Pseudo dice [0.9535, 0.8348, 0.8618, 0.908, nan, 0.4821, 0.8772, 0.8733, 0.8422, 0.8096, 0.9022, 0.8888] 
2025-02-25 10:30:27.060828: Epoch time: 397.33 s 
2025-02-25 10:30:27.084479: Yayy! New best EMA pseudo Dice: 0.7274 
2025-02-25 10:30:31.756668:  
2025-02-25 10:30:31.763652: Epoch 17 
2025-02-25 10:30:31.769362: Current learning rate: 0.00985 
2025-02-25 10:37:12.691311: train_loss -0.7061 
2025-02-25 10:37:12.697380: val_loss -0.6339 
2025-02-25 10:37:12.704295: Pseudo dice [0.954, 0.8355, 0.8572, 0.9062, nan, 0.4437, 0.871, 0.8685, 0.8424, 0.7976, 0.9, 0.8885] 
2025-02-25 10:37:12.729117: Epoch time: 400.94 s 
2025-02-25 10:37:12.735118: Yayy! New best EMA pseudo Dice: 0.738 
2025-02-25 10:37:18.179409:  
2025-02-25 10:37:18.185442: Epoch 18 
2025-02-25 10:37:18.191525: Current learning rate: 0.00984 
2025-02-25 10:43:56.663783: train_loss -0.7091 
2025-02-25 10:43:56.672187: val_loss -0.6305 
2025-02-25 10:43:56.678745: Pseudo dice [0.9528, 0.8295, 0.855, 0.9053, nan, 0.4456, 0.8741, 0.8695, 0.8378, 0.7981, 0.9012, 0.8867] 
2025-02-25 10:43:56.683776: Epoch time: 398.49 s 
2025-02-25 10:43:56.690255: Yayy! New best EMA pseudo Dice: 0.7474 
2025-02-25 10:44:01.619808:  
2025-02-25 10:44:01.625607: Epoch 19 
2025-02-25 10:44:01.630663: Current learning rate: 0.00983 
2025-02-25 10:50:43.808044: train_loss -0.7143 
2025-02-25 10:50:43.817081: val_loss -0.6303 
2025-02-25 10:50:43.829556: Pseudo dice [0.9533, 0.8367, 0.8589, 0.9032, nan, 0.4487, 0.8709, 0.8683, 0.8432, 0.8009, 0.8991, 0.8869] 
2025-02-25 10:50:43.838856: Epoch time: 402.19 s 
2025-02-25 10:50:43.847480: Yayy! New best EMA pseudo Dice: 0.7561 
2025-02-25 10:50:48.005836:  
2025-02-25 10:50:48.012387: Epoch 20 
2025-02-25 10:50:48.018381: Current learning rate: 0.00982 
2025-02-25 10:57:25.437508: train_loss -0.7152 
2025-02-25 10:57:25.443549: val_loss -0.6362 
2025-02-25 10:57:25.450211: Pseudo dice [0.9538, 0.8374, 0.859, 0.9059, nan, 0.459, 0.8749, 0.872, 0.8422, 0.7989, 0.9037, 0.8908] 
2025-02-25 10:57:25.459363: Epoch time: 397.43 s 
2025-02-25 10:57:25.466098: Yayy! New best EMA pseudo Dice: 0.7641 
2025-02-25 10:57:30.941153:  
2025-02-25 10:57:30.947295: Epoch 21 
2025-02-25 10:57:30.955781: Current learning rate: 0.00981 
2025-02-25 11:04:04.731817: train_loss -0.7178 
2025-02-25 11:04:04.737123: val_loss -0.628 
2025-02-25 11:04:04.744784: Pseudo dice [0.9529, 0.8334, 0.855, 0.9038, nan, 0.4426, 0.8734, 0.8694, 0.8421, 0.8003, 0.8988, 0.8859] 
2025-02-25 11:04:04.751773: Epoch time: 393.79 s 
2025-02-25 11:04:04.757531: Yayy! New best EMA pseudo Dice: 0.7709 
2025-02-25 11:04:09.058552:  
2025-02-25 11:04:09.064366: Epoch 22 
2025-02-25 11:04:09.071510: Current learning rate: 0.0098 
2025-02-25 11:10:49.207122: train_loss -0.7194 
2025-02-25 11:10:49.215036: val_loss -0.6232 
2025-02-25 11:10:49.221505: Pseudo dice [0.9523, 0.832, 0.857, 0.9046, nan, 0.4269, 0.8692, 0.8683, 0.8402, 0.7955, 0.8976, 0.8868] 
2025-02-25 11:10:49.226322: Epoch time: 400.15 s 
2025-02-25 11:10:49.232422: Yayy! New best EMA pseudo Dice: 0.7768 
2025-02-25 11:10:53.988276:  
2025-02-25 11:10:53.994243: Epoch 23 
2025-02-25 11:10:54.000230: Current learning rate: 0.00979 
2025-02-25 11:17:35.714385: train_loss -0.7227 
2025-02-25 11:17:35.722265: val_loss -0.625 
2025-02-25 11:17:35.729206: Pseudo dice [0.9528, 0.8313, 0.8519, 0.905, nan, 0.4371, 0.8704, 0.8679, 0.8363, 0.7963, 0.9003, 0.8875] 
2025-02-25 11:17:35.752186: Epoch time: 401.73 s 
2025-02-25 11:17:35.757648: Yayy! New best EMA pseudo Dice: 0.7822 
2025-02-25 11:17:40.047472:  
2025-02-25 11:17:40.054208: Epoch 24 
2025-02-25 11:17:40.060335: Current learning rate: 0.00978 
2025-02-25 11:24:22.944140: train_loss -0.7252 
2025-02-25 11:24:22.953518: val_loss -0.6241 
2025-02-25 11:24:22.961141: Pseudo dice [0.9524, 0.8352, 0.8526, 0.9048, nan, 0.4493, 0.8705, 0.8694, 0.8351, 0.7929, 0.9013, 0.8867] 
2025-02-25 11:24:22.967247: Epoch time: 402.9 s 
2025-02-25 11:24:22.975717: Yayy! New best EMA pseudo Dice: 0.7872 
2025-02-25 11:24:27.404040:  
2025-02-25 11:24:27.409586: Epoch 25 
2025-02-25 11:24:27.415699: Current learning rate: 0.00977 
2025-02-25 11:31:32.003384: train_loss -0.7273 
2025-02-25 11:31:32.011870: val_loss -0.6251 
2025-02-25 11:31:32.018494: Pseudo dice [0.9538, 0.8337, 0.8556, 0.9038, nan, 0.434, 0.8736, 0.8689, 0.8389, 0.7965, 0.8987, 0.8878] 
2025-02-25 11:31:32.038546: Epoch time: 424.6 s 
2025-02-25 11:31:32.046002: Yayy! New best EMA pseudo Dice: 0.7916 
2025-02-25 11:31:36.784567:  
2025-02-25 11:31:36.791871: Epoch 26 
2025-02-25 11:31:36.797862: Current learning rate: 0.00977 
2025-02-25 11:38:59.107964: train_loss -0.7279 
2025-02-25 11:38:59.115493: val_loss -0.6263 
2025-02-25 11:38:59.124751: Pseudo dice [0.951, 0.8351, 0.8568, 0.9054, nan, 0.4378, 0.8711, 0.8687, 0.843, 0.7962, 0.9009, 0.8872] 
2025-02-25 11:38:59.130829: Epoch time: 442.33 s 
2025-02-25 11:38:59.137526: Yayy! New best EMA pseudo Dice: 0.7956 
2025-02-25 11:39:03.834436:  
2025-02-25 11:39:03.840853: Epoch 27 
2025-02-25 11:39:03.847813: Current learning rate: 0.00976 
2025-02-25 11:46:11.309021: train_loss -0.7306 
2025-02-25 11:46:11.315194: val_loss -0.6187 
2025-02-25 11:46:11.321664: Pseudo dice [0.954, 0.8332, 0.857, 0.9023, nan, 0.4165, 0.8713, 0.8681, 0.8453, 0.8001, 0.9021, 0.8863] 
2025-02-25 11:46:11.328452: Epoch time: 427.48 s 
2025-02-25 11:46:11.334702: Yayy! New best EMA pseudo Dice: 0.7991 
2025-02-25 11:46:15.925749:  
2025-02-25 11:46:15.932754: Epoch 28 
2025-02-25 11:46:15.938164: Current learning rate: 0.00975 
2025-02-25 11:53:15.700390: train_loss -0.7339 
2025-02-25 11:53:15.708669: val_loss -0.6196 
2025-02-25 11:53:15.714380: Pseudo dice [0.9535, 0.8359, 0.8551, 0.9031, nan, 0.4249, 0.8713, 0.8691, 0.8387, 0.795, 0.9018, 0.8869] 
2025-02-25 11:53:15.723796: Epoch time: 419.78 s 
2025-02-25 11:53:15.729330: Yayy! New best EMA pseudo Dice: 0.8023 
2025-02-25 11:53:20.241577:  
2025-02-25 11:53:20.249937: Epoch 29 
2025-02-25 11:53:20.256850: Current learning rate: 0.00974 
2025-02-25 12:00:18.632511: train_loss -0.7338 
2025-02-25 12:00:18.639482: val_loss -0.6189 
2025-02-25 12:00:18.645481: Pseudo dice [0.9538, 0.8326, 0.8539, 0.9043, nan, 0.4195, 0.8738, 0.8686, 0.8417, 0.8025, 0.9003, 0.8875] 
2025-02-25 12:00:18.651401: Epoch time: 418.39 s 
2025-02-25 12:00:18.656582: Yayy! New best EMA pseudo Dice: 0.8051 
2025-02-25 12:00:25.360377:  
2025-02-25 12:00:25.374017: Epoch 30 
2025-02-25 12:00:25.382329: Current learning rate: 0.00973 
2025-02-25 12:07:21.073055: train_loss -0.7371 
2025-02-25 12:07:21.087309: val_loss -0.6128 
2025-02-25 12:07:21.094784: Pseudo dice [0.9528, 0.8305, 0.8536, 0.9043, nan, 0.4265, 0.8687, 0.8637, 0.8408, 0.7919, 0.8994, 0.8845] 
2025-02-25 12:07:21.102471: Epoch time: 415.71 s 
2025-02-25 12:07:21.112008: Yayy! New best EMA pseudo Dice: 0.8075 
2025-02-25 12:07:27.771788:  
2025-02-25 12:07:27.778075: Epoch 31 
2025-02-25 12:07:27.783062: Current learning rate: 0.00972 
2025-02-25 12:14:15.987909: train_loss -0.7379 
2025-02-25 12:14:15.993664: val_loss -0.6197 
2025-02-25 12:14:16.001534: Pseudo dice [0.9542, 0.8362, 0.8591, 0.9038, nan, 0.4293, 0.872, 0.8699, 0.845, 0.8006, 0.901, 0.8864] 
2025-02-25 12:14:16.008533: Epoch time: 408.22 s 
2025-02-25 12:14:16.014277: Yayy! New best EMA pseudo Dice: 0.81 
2025-02-25 12:14:21.245479:  
2025-02-25 12:14:21.254062: Epoch 32 
2025-02-25 12:14:21.261518: Current learning rate: 0.00971 
2025-02-25 12:21:11.791071: train_loss -0.741 
2025-02-25 12:21:11.799657: val_loss -0.6215 
2025-02-25 12:21:11.809213: Pseudo dice [0.954, 0.8365, 0.8549, 0.9051, nan, 0.4543, 0.8727, 0.8678, 0.8439, 0.798, 0.902, 0.8858] 
2025-02-25 12:21:11.818831: Epoch time: 410.55 s 
2025-02-25 12:21:11.823095: Yayy! New best EMA pseudo Dice: 0.8124 
2025-02-25 12:21:16.958074:  
2025-02-25 12:21:16.965314: Epoch 33 
2025-02-25 12:21:16.970555: Current learning rate: 0.0097 
2025-02-25 12:28:05.082317: train_loss -0.7423 
2025-02-25 12:28:05.089130: val_loss -0.6142 
2025-02-25 12:28:05.097472: Pseudo dice [0.9541, 0.8318, 0.8544, 0.9024, nan, 0.4214, 0.872, 0.8654, 0.8398, 0.7925, 0.9008, 0.8853] 
2025-02-25 12:28:05.104703: Epoch time: 408.13 s 
2025-02-25 12:28:05.111413: Yayy! New best EMA pseudo Dice: 0.8141 
2025-02-25 12:28:11.150409:  
2025-02-25 12:28:11.157766: Epoch 34 
2025-02-25 12:28:11.167873: Current learning rate: 0.00969 
2025-02-25 12:34:52.884019: train_loss -0.7432 
2025-02-25 12:34:52.899730: val_loss -0.6094 
2025-02-25 12:34:52.907802: Pseudo dice [0.9525, 0.8354, 0.8524, 0.9038, nan, 0.4232, 0.8738, 0.8647, 0.8355, 0.7944, 0.8981, 0.8818] 
2025-02-25 12:34:52.915888: Epoch time: 401.74 s 
2025-02-25 12:34:52.920622: Yayy! New best EMA pseudo Dice: 0.8155 
2025-02-25 12:34:57.487318:  
2025-02-25 12:34:57.494578: Epoch 35 
2025-02-25 12:34:57.502311: Current learning rate: 0.00968 
2025-02-25 12:41:42.394966: train_loss -0.7441 
2025-02-25 12:41:42.402106: val_loss -0.6088 
2025-02-25 12:41:42.411305: Pseudo dice [0.9535, 0.836, 0.8574, 0.9029, nan, 0.4184, 0.8693, 0.8673, 0.8411, 0.7928, 0.8987, 0.8856] 
2025-02-25 12:41:42.417850: Epoch time: 404.91 s 
2025-02-25 12:41:42.424313: Yayy! New best EMA pseudo Dice: 0.8169 
2025-02-25 12:41:46.717809:  
2025-02-25 12:41:46.723690: Epoch 36 
2025-02-25 12:41:46.730098: Current learning rate: 0.00968 
2025-02-25 12:48:25.804384: train_loss -0.7463 
2025-02-25 12:48:25.819239: val_loss -0.6103 
2025-02-25 12:48:25.826681: Pseudo dice [0.9529, 0.8279, 0.852, 0.9002, nan, 0.4195, 0.8715, 0.8687, 0.8442, 0.8002, 0.9012, 0.8862] 
2025-02-25 12:48:25.831553: Epoch time: 399.09 s 
2025-02-25 12:48:25.839826: Yayy! New best EMA pseudo Dice: 0.8182 
2025-02-25 12:48:30.631301:  
2025-02-25 12:48:30.637116: Epoch 37 
2025-02-25 12:48:30.642768: Current learning rate: 0.00967 
2025-02-25 12:55:27.298049: train_loss -0.7488 
2025-02-25 12:55:27.305209: val_loss -0.6093 
2025-02-25 12:55:27.310812: Pseudo dice [0.9542, 0.834, 0.8567, 0.9026, nan, 0.3999, 0.8721, 0.8671, 0.8455, 0.797, 0.9005, 0.8881] 
2025-02-25 12:55:27.318985: Epoch time: 416.67 s 
2025-02-25 12:55:27.325427: Yayy! New best EMA pseudo Dice: 0.8192 
2025-02-25 12:55:33.158027:  
2025-02-25 12:55:33.164909: Epoch 38 
2025-02-25 12:55:33.174996: Current learning rate: 0.00966 
2025-02-25 13:02:32.890586: train_loss -0.7508 
2025-02-25 13:02:32.897548: val_loss -0.6061 
2025-02-25 13:02:32.917922: Pseudo dice [0.9523, 0.8295, 0.8553, 0.9016, nan, 0.4077, 0.8712, 0.8647, 0.844, 0.8041, 0.901, 0.8857] 
2025-02-25 13:02:32.922715: Epoch time: 419.74 s 
2025-02-25 13:02:32.930941: Yayy! New best EMA pseudo Dice: 0.8202 
2025-02-25 13:02:37.448441:  
2025-02-25 13:02:37.455140: Epoch 39 
2025-02-25 13:02:37.460769: Current learning rate: 0.00965 
2025-02-25 13:09:33.902784: train_loss -0.7511 
2025-02-25 13:09:33.909991: val_loss -0.604 
2025-02-25 13:09:33.914665: Pseudo dice [0.9512, 0.8298, 0.8539, 0.9028, nan, 0.4231, 0.8717, 0.8645, 0.8383, 0.7989, 0.8986, 0.8838] 
2025-02-25 13:09:33.921715: Epoch time: 416.46 s 
2025-02-25 13:09:33.929350: Yayy! New best EMA pseudo Dice: 0.8211 
2025-02-25 13:09:38.841578:  
2025-02-25 13:09:38.848926: Epoch 40 
2025-02-25 13:09:38.852263: Current learning rate: 0.00964 
2025-02-25 13:16:19.893398: train_loss -0.7519 
2025-02-25 13:16:19.899146: val_loss -0.6043 
2025-02-25 13:16:19.906089: Pseudo dice [0.9523, 0.8287, 0.8551, 0.9019, nan, 0.4045, 0.8731, 0.8663, 0.8415, 0.8018, 0.9007, 0.8868] 
2025-02-25 13:16:19.911485: Epoch time: 401.05 s 
2025-02-25 13:16:19.917073: Yayy! New best EMA pseudo Dice: 0.8218 
2025-02-25 13:16:24.548305:  
2025-02-25 13:16:24.552753: Epoch 41 
2025-02-25 13:16:24.558501: Current learning rate: 0.00963 
2025-02-25 13:22:58.639555: train_loss -0.7535 
2025-02-25 13:22:58.648128: val_loss -0.6057 
2025-02-25 13:22:58.651437: Pseudo dice [0.9517, 0.8309, 0.8566, 0.9038, nan, 0.4191, 0.8687, 0.8656, 0.8455, 0.7969, 0.8991, 0.8835] 
2025-02-25 13:22:58.653405: Epoch time: 394.1 s 
2025-02-25 13:22:58.671290: Yayy! New best EMA pseudo Dice: 0.8225 
2025-02-25 13:23:03.533247:  
2025-02-25 13:23:03.542855: Epoch 42 
2025-02-25 13:23:03.551913: Current learning rate: 0.00962 
2025-02-25 13:29:43.471948: train_loss -0.7567 
2025-02-25 13:29:43.483732: val_loss -0.6023 
2025-02-25 13:29:43.490890: Pseudo dice [0.9537, 0.8282, 0.8556, 0.9026, nan, 0.4106, 0.8711, 0.8658, 0.8372, 0.8007, 0.9008, 0.8845] 
2025-02-25 13:29:43.500529: Epoch time: 399.94 s 
2025-02-25 13:29:43.508355: Yayy! New best EMA pseudo Dice: 0.8231 
2025-02-25 13:29:48.551270:  
2025-02-25 13:29:48.557337: Epoch 43 
2025-02-25 13:29:48.562169: Current learning rate: 0.00961 
2025-02-25 13:36:32.364172: train_loss -0.7573 
2025-02-25 13:36:32.377767: val_loss -0.5997 
2025-02-25 13:36:32.389882: Pseudo dice [0.9539, 0.8284, 0.8538, 0.9016, nan, 0.404, 0.8723, 0.8677, 0.8372, 0.7944, 0.8998, 0.8859] 
2025-02-25 13:36:32.403014: Epoch time: 403.82 s 
2025-02-25 13:36:32.410891: Yayy! New best EMA pseudo Dice: 0.8235 
2025-02-25 13:36:38.613589:  
2025-02-25 13:36:38.620496: Epoch 44 
2025-02-25 13:36:38.628832: Current learning rate: 0.0096 
2025-02-25 13:43:16.061589: train_loss -0.7585 
2025-02-25 13:43:16.068271: val_loss -0.5937 
2025-02-25 13:43:16.075368: Pseudo dice [0.9523, 0.8278, 0.8524, 0.9017, nan, 0.3868, 0.8703, 0.8629, 0.8409, 0.7967, 0.9002, 0.8834] 
2025-02-25 13:43:16.096363: Epoch time: 397.45 s 
2025-02-25 13:43:16.102336: Yayy! New best EMA pseudo Dice: 0.8237 
2025-02-25 13:43:21.508342:  
2025-02-25 13:43:21.516480: Epoch 45 
2025-02-25 13:43:21.521830: Current learning rate: 0.00959 
2025-02-25 13:49:56.359455: train_loss -0.7611 
2025-02-25 13:49:56.366789: val_loss -0.6012 
2025-02-25 13:49:56.375137: Pseudo dice [0.9531, 0.8344, 0.8531, 0.9017, nan, 0.4337, 0.8717, 0.8622, 0.842, 0.7978, 0.8991, 0.8832] 
2025-02-25 13:49:56.381081: Epoch time: 394.85 s 
2025-02-25 13:49:56.386501: Yayy! New best EMA pseudo Dice: 0.8243 
2025-02-25 13:50:00.707761:  
2025-02-25 13:50:00.715199: Epoch 46 
2025-02-25 13:50:00.720811: Current learning rate: 0.00959 
2025-02-25 13:56:35.324963: train_loss -0.7614 
2025-02-25 13:56:35.352105: val_loss -0.5965 
2025-02-25 13:56:35.359719: Pseudo dice [0.9522, 0.8291, 0.8521, 0.9014, nan, 0.4182, 0.8694, 0.8631, 0.84, 0.7947, 0.8986, 0.8828] 
2025-02-25 13:56:35.365957: Epoch time: 394.62 s 
2025-02-25 13:56:35.374818: Yayy! New best EMA pseudo Dice: 0.8246 
2025-02-25 13:56:40.167850:  
2025-02-25 13:56:40.178588: Epoch 47 
2025-02-25 13:56:40.185294: Current learning rate: 0.00958 
2025-02-25 14:03:12.163079: train_loss -0.7627 
2025-02-25 14:03:12.169781: val_loss -0.6054 
2025-02-25 14:03:12.178382: Pseudo dice [0.9514, 0.8297, 0.8561, 0.9038, nan, 0.4479, 0.8721, 0.8655, 0.8469, 0.7987, 0.9009, 0.8844] 
2025-02-25 14:03:12.186768: Epoch time: 392.0 s 
2025-02-25 14:03:12.192197: Yayy! New best EMA pseudo Dice: 0.8254 
2025-02-25 14:03:16.911784:  
2025-02-25 14:03:16.918299: Epoch 48 
2025-02-25 14:03:16.923705: Current learning rate: 0.00957 
2025-02-25 14:09:56.261472: train_loss -0.7629 
2025-02-25 14:09:56.269869: val_loss -0.5954 
2025-02-25 14:09:56.276120: Pseudo dice [0.9538, 0.8318, 0.8546, 0.9009, nan, 0.3913, 0.8717, 0.8639, 0.8428, 0.8001, 0.9005, 0.8837] 
2025-02-25 14:09:56.282758: Epoch time: 399.35 s 
2025-02-25 14:09:56.288282: Yayy! New best EMA pseudo Dice: 0.8256 
2025-02-25 14:10:01.059214:  
2025-02-25 14:10:01.065797: Epoch 49 
2025-02-25 14:10:01.073681: Current learning rate: 0.00956 
2025-02-25 14:16:44.357820: train_loss -0.7637 
2025-02-25 14:16:44.363853: val_loss -0.5992 
2025-02-25 14:16:44.368827: Pseudo dice [0.9525, 0.8329, 0.8558, 0.9029, nan, 0.4326, 0.8748, 0.8641, 0.8405, 0.7986, 0.8988, 0.8828] 
2025-02-25 14:16:44.375719: Epoch time: 403.3 s 
2025-02-25 14:16:46.201831: Yayy! New best EMA pseudo Dice: 0.8261 
2025-02-25 14:16:50.924582:  
2025-02-25 14:16:50.929457: Epoch 50 
2025-02-25 14:16:50.935925: Current learning rate: 0.00955 
2025-02-25 14:23:37.712481: train_loss -0.7644 
2025-02-25 14:23:37.718619: val_loss -0.5921 
2025-02-25 14:23:37.726512: Pseudo dice [0.9534, 0.832, 0.8533, 0.9001, nan, 0.3798, 0.8698, 0.8638, 0.8424, 0.8006, 0.9001, 0.8836] 
2025-02-25 14:23:37.731506: Epoch time: 406.79 s 
2025-02-25 14:23:39.997513:  
2025-02-25 14:23:40.004730: Epoch 51 
2025-02-25 14:23:40.012410: Current learning rate: 0.00954 
2025-02-25 14:30:11.251302: train_loss -0.7658 
2025-02-25 14:30:11.263576: val_loss -0.5947 
2025-02-25 14:30:11.274542: Pseudo dice [0.954, 0.8329, 0.8569, 0.9044, nan, 0.3845, 0.8738, 0.8678, 0.8487, 0.7979, 0.9016, 0.8839] 
2025-02-25 14:30:11.282876: Epoch time: 391.26 s 
2025-02-25 14:30:11.294392: Yayy! New best EMA pseudo Dice: 0.8262 
2025-02-25 14:30:16.438442:  
2025-02-25 14:30:16.446682: Epoch 52 
2025-02-25 14:30:16.471261: Current learning rate: 0.00953 
2025-02-25 14:36:54.170164: train_loss -0.7668 
2025-02-25 14:36:54.178868: val_loss -0.5937 
2025-02-25 14:36:54.186598: Pseudo dice [0.9516, 0.8318, 0.8562, 0.9043, nan, 0.3963, 0.871, 0.8648, 0.8418, 0.7994, 0.9001, 0.8836] 
2025-02-25 14:36:54.193244: Epoch time: 397.73 s 
2025-02-25 14:36:54.199104: Yayy! New best EMA pseudo Dice: 0.8263 
2025-02-25 14:37:00.415728:  
2025-02-25 14:37:00.444196: Epoch 53 
2025-02-25 14:37:00.455356: Current learning rate: 0.00952 
2025-02-25 14:43:38.676008: train_loss -0.7672 
2025-02-25 14:43:38.682530: val_loss -0.597 
2025-02-25 14:43:38.690462: Pseudo dice [0.9521, 0.8349, 0.8572, 0.9006, nan, 0.4274, 0.8719, 0.8614, 0.8448, 0.7965, 0.9012, 0.8866] 
2025-02-25 14:43:38.695313: Epoch time: 398.26 s 
2025-02-25 14:43:38.700764: Yayy! New best EMA pseudo Dice: 0.8267 
2025-02-25 14:43:42.917039:  
2025-02-25 14:43:42.923459: Epoch 54 
2025-02-25 14:43:42.929807: Current learning rate: 0.00951 
2025-02-25 14:50:27.190510: train_loss -0.7688 
2025-02-25 14:50:27.198584: val_loss -0.5918 
2025-02-25 14:50:27.207644: Pseudo dice [0.9521, 0.8316, 0.8539, 0.9011, nan, 0.3963, 0.8712, 0.8667, 0.8402, 0.7963, 0.901, 0.8874] 
2025-02-25 14:50:27.216491: Epoch time: 404.28 s 
2025-02-25 14:50:27.223159: Yayy! New best EMA pseudo Dice: 0.8267 
2025-02-25 14:50:31.527602:  
2025-02-25 14:50:31.533158: Epoch 55 
2025-02-25 14:50:31.540540: Current learning rate: 0.0095 
2025-02-25 14:57:17.349511: train_loss -0.7692 
2025-02-25 14:57:17.356605: val_loss -0.5953 
2025-02-25 14:57:17.361805: Pseudo dice [0.9543, 0.8332, 0.8597, 0.9033, nan, 0.3978, 0.8741, 0.8645, 0.8436, 0.7999, 0.9015, 0.8858] 
2025-02-25 14:57:17.369260: Epoch time: 405.83 s 
2025-02-25 14:57:17.376024: Yayy! New best EMA pseudo Dice: 0.827 
2025-02-25 14:57:23.181253:  
2025-02-25 14:57:23.187087: Epoch 56 
2025-02-25 14:57:23.207238: Current learning rate: 0.00949 
2025-02-25 15:04:02.259074: train_loss -0.7712 
2025-02-25 15:04:02.266515: val_loss -0.5835 
2025-02-25 15:04:02.272891: Pseudo dice [0.9525, 0.8276, 0.8533, 0.9029, nan, 0.3935, 0.8711, 0.861, 0.8364, 0.7971, 0.8981, 0.885] 
2025-02-25 15:04:02.277895: Epoch time: 399.08 s 
2025-02-25 15:04:06.085202:  
2025-02-25 15:04:06.090872: Epoch 57 
2025-02-25 15:04:06.094420: Current learning rate: 0.00949 
2025-02-25 15:37:59.425430: train_loss -0.771 
2025-02-25 15:37:59.444981: val_loss -0.588 
2025-02-25 15:37:59.450793: Pseudo dice [0.9529, 0.8316, 0.8555, 0.9011, nan, 0.4043, 0.8714, 0.864, 0.8431, 0.7963, 0.8998, 0.8832] 
2025-02-25 15:37:59.456372: Epoch time: 2033.34 s 
2025-02-25 15:38:01.986099:  
2025-02-25 15:38:02.008126: Epoch 58 
2025-02-25 15:38:02.013629: Current learning rate: 0.00948 
2025-02-25 15:44:39.163278: train_loss -0.7727 
2025-02-25 15:44:39.176126: val_loss -0.5795 
2025-02-25 15:44:39.186367: Pseudo dice [0.9526, 0.8265, 0.8504, 0.8998, nan, 0.4065, 0.8671, 0.8586, 0.8336, 0.7878, 0.8975, 0.8818] 
2025-02-25 15:44:39.196310: Epoch time: 397.18 s 
2025-02-25 15:44:42.855298:  
2025-02-25 15:44:42.861019: Epoch 59 
2025-02-25 15:44:42.866604: Current learning rate: 0.00947 
2025-02-25 15:51:18.072708: train_loss -0.7727 
2025-02-25 15:51:18.084254: val_loss -0.585 
2025-02-25 15:51:18.092191: Pseudo dice [0.9504, 0.8306, 0.8555, 0.9035, nan, 0.4125, 0.8709, 0.8589, 0.8439, 0.7991, 0.8988, 0.8823] 
2025-02-25 15:51:18.101366: Epoch time: 395.22 s 
2025-02-25 15:51:20.820803:  
2025-02-25 15:51:20.826816: Epoch 60 
2025-02-25 15:51:20.831378: Current learning rate: 0.00946 
2025-02-25 15:57:54.377470: train_loss -0.7739 
2025-02-25 15:57:54.384001: val_loss -0.5787 
2025-02-25 15:57:54.392345: Pseudo dice [0.951, 0.8268, 0.8524, 0.9004, nan, 0.4035, 0.8656, 0.8605, 0.8386, 0.7926, 0.8993, 0.8822] 
2025-02-25 15:57:54.399832: Epoch time: 393.56 s 
2025-02-25 15:57:56.782770:  
2025-02-25 15:57:56.787415: Epoch 61 
2025-02-25 15:57:56.795177: Current learning rate: 0.00945 
2025-02-25 16:04:25.844969: train_loss -0.7761 
2025-02-25 16:04:25.852449: val_loss -0.5799 
2025-02-25 16:04:25.858247: Pseudo dice [0.9519, 0.8337, 0.8518, 0.9, nan, 0.4013, 0.8693, 0.8593, 0.8388, 0.7967, 0.8975, 0.8819] 
2025-02-25 16:04:25.863450: Epoch time: 389.07 s 
2025-02-25 16:04:30.068462:  
2025-02-25 16:04:30.077440: Epoch 62 
2025-02-25 16:04:30.084012: Current learning rate: 0.00944 
2025-02-25 16:11:02.745570: train_loss -0.7765 
2025-02-25 16:11:02.751864: val_loss -0.5803 
2025-02-25 16:11:02.758866: Pseudo dice [0.951, 0.8339, 0.8565, 0.9026, nan, 0.3966, 0.8698, 0.8613, 0.8427, 0.8022, 0.8989, 0.8835] 
2025-02-25 16:11:02.766845: Epoch time: 392.69 s 
2025-02-25 16:11:05.280318:  
2025-02-25 16:11:05.288010: Epoch 63 
2025-02-25 16:11:05.293718: Current learning rate: 0.00943 
2025-02-25 16:17:39.992163: train_loss -0.7778 
2025-02-25 16:17:40.001615: val_loss -0.5873 
2025-02-25 16:17:40.010761: Pseudo dice [0.9514, 0.8302, 0.8575, 0.9039, nan, 0.4242, 0.8721, 0.8634, 0.843, 0.8007, 0.8989, 0.8838] 
2025-02-25 16:17:40.021001: Epoch time: 394.71 s 
2025-02-25 16:17:42.543061:  
2025-02-25 16:17:42.548851: Epoch 64 
2025-02-25 16:17:42.556469: Current learning rate: 0.00942 
2025-02-25 16:24:12.387061: train_loss -0.7787 
2025-02-25 16:24:12.399192: val_loss -0.5879 
2025-02-25 16:24:12.407127: Pseudo dice [0.9539, 0.8321, 0.8547, 0.9038, nan, 0.4153, 0.8762, 0.8629, 0.8466, 0.798, 0.9, 0.8831] 
2025-02-25 16:24:12.413751: Epoch time: 389.84 s 
2025-02-25 16:24:12.420186: Yayy! New best EMA pseudo Dice: 0.8271 
2025-02-25 16:24:18.282684:  
2025-02-25 16:24:18.290714: Epoch 65 
2025-02-25 16:24:18.307359: Current learning rate: 0.00941 
